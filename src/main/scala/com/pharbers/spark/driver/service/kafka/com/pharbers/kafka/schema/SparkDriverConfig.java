/**
 * Autogenerated by Avro
 *
 * DO NOT EDIT DIRECTLY
 */
package com.pharbers.kafka.schema;

import org.apache.avro.specific.SpecificData;

@SuppressWarnings("all")
@org.apache.avro.specific.AvroGenerated
public class SparkDriverConfig extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  private static final long serialVersionUID = 1354731696283109989L;
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"SparkDriverConfig\",\"namespace\":\"com.pharbers.kafka.schema\",\"fields\":[{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"cup\",\"type\":\"int\"},{\"name\":\"eme\",\"type\":\"int\"},{\"name\":\"topic\",\"type\":\"string\"}]}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
  @Deprecated public java.lang.CharSequence name;
  @Deprecated public int cup;
  @Deprecated public int eme;
  @Deprecated public java.lang.CharSequence topic;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>.
   */
  public SparkDriverConfig() {}

  /**
   * All-args constructor.
   * @param name The new value for name
   * @param cup The new value for cup
   * @param eme The new value for eme
   * @param topic The new value for topic
   */
  public SparkDriverConfig(java.lang.CharSequence name, java.lang.Integer cup, java.lang.Integer eme, java.lang.CharSequence topic) {
    this.name = name;
    this.cup = cup;
    this.eme = eme;
    this.topic = topic;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call.
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return name;
    case 1: return cup;
    case 2: return eme;
    case 3: return topic;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  // Used by DatumReader.  Applications should not call.
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: name = (java.lang.CharSequence)value$; break;
    case 1: cup = (java.lang.Integer)value$; break;
    case 2: eme = (java.lang.Integer)value$; break;
    case 3: topic = (java.lang.CharSequence)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'name' field.
   * @return The value of the 'name' field.
   */
  public java.lang.CharSequence getName() {
    return name;
  }

  /**
   * Sets the value of the 'name' field.
   * @param value the value to set.
   */
  public void setName(java.lang.CharSequence value) {
    this.name = value;
  }

  /**
   * Gets the value of the 'cup' field.
   * @return The value of the 'cup' field.
   */
  public java.lang.Integer getCup() {
    return cup;
  }

  /**
   * Sets the value of the 'cup' field.
   * @param value the value to set.
   */
  public void setCup(java.lang.Integer value) {
    this.cup = value;
  }

  /**
   * Gets the value of the 'eme' field.
   * @return The value of the 'eme' field.
   */
  public java.lang.Integer getEme() {
    return eme;
  }

  /**
   * Sets the value of the 'eme' field.
   * @param value the value to set.
   */
  public void setEme(java.lang.Integer value) {
    this.eme = value;
  }

  /**
   * Gets the value of the 'topic' field.
   * @return The value of the 'topic' field.
   */
  public java.lang.CharSequence getTopic() {
    return topic;
  }

  /**
   * Sets the value of the 'topic' field.
   * @param value the value to set.
   */
  public void setTopic(java.lang.CharSequence value) {
    this.topic = value;
  }

  /**
   * Creates a new SparkDriverConfig RecordBuilder.
   * @return A new SparkDriverConfig RecordBuilder
   */
  public static com.pharbers.kafka.schema.SparkDriverConfig.Builder newBuilder() {
    return new com.pharbers.kafka.schema.SparkDriverConfig.Builder();
  }

  /**
   * Creates a new SparkDriverConfig RecordBuilder by copying an existing Builder.
   * @param other The existing builder to copy.
   * @return A new SparkDriverConfig RecordBuilder
   */
  public static com.pharbers.kafka.schema.SparkDriverConfig.Builder newBuilder(com.pharbers.kafka.schema.SparkDriverConfig.Builder other) {
    return new com.pharbers.kafka.schema.SparkDriverConfig.Builder(other);
  }

  /**
   * Creates a new SparkDriverConfig RecordBuilder by copying an existing SparkDriverConfig instance.
   * @param other The existing instance to copy.
   * @return A new SparkDriverConfig RecordBuilder
   */
  public static com.pharbers.kafka.schema.SparkDriverConfig.Builder newBuilder(com.pharbers.kafka.schema.SparkDriverConfig other) {
    return new com.pharbers.kafka.schema.SparkDriverConfig.Builder(other);
  }

  /**
   * RecordBuilder for SparkDriverConfig instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<SparkDriverConfig>
    implements org.apache.avro.data.RecordBuilder<SparkDriverConfig> {

    private java.lang.CharSequence name;
    private int cup;
    private int eme;
    private java.lang.CharSequence topic;

    /** Creates a new Builder */
    private Builder() {
      super(SCHEMA$);
    }

    /**
     * Creates a Builder by copying an existing Builder.
     * @param other The existing Builder to copy.
     */
    private Builder(com.pharbers.kafka.schema.SparkDriverConfig.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.name)) {
        this.name = data().deepCopy(fields()[0].schema(), other.name);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.cup)) {
        this.cup = data().deepCopy(fields()[1].schema(), other.cup);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.eme)) {
        this.eme = data().deepCopy(fields()[2].schema(), other.eme);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.topic)) {
        this.topic = data().deepCopy(fields()[3].schema(), other.topic);
        fieldSetFlags()[3] = true;
      }
    }

    /**
     * Creates a Builder by copying an existing SparkDriverConfig instance
     * @param other The existing instance to copy.
     */
    private Builder(com.pharbers.kafka.schema.SparkDriverConfig other) {
            super(SCHEMA$);
      if (isValidValue(fields()[0], other.name)) {
        this.name = data().deepCopy(fields()[0].schema(), other.name);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.cup)) {
        this.cup = data().deepCopy(fields()[1].schema(), other.cup);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.eme)) {
        this.eme = data().deepCopy(fields()[2].schema(), other.eme);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.topic)) {
        this.topic = data().deepCopy(fields()[3].schema(), other.topic);
        fieldSetFlags()[3] = true;
      }
    }

    /**
      * Gets the value of the 'name' field.
      * @return The value.
      */
    public java.lang.CharSequence getName() {
      return name;
    }

    /**
      * Sets the value of the 'name' field.
      * @param value The value of 'name'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder setName(java.lang.CharSequence value) {
      validate(fields()[0], value);
      this.name = value;
      fieldSetFlags()[0] = true;
      return this;
    }

    /**
      * Checks whether the 'name' field has been set.
      * @return True if the 'name' field has been set, false otherwise.
      */
    public boolean hasName() {
      return fieldSetFlags()[0];
    }


    /**
      * Clears the value of the 'name' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder clearName() {
      name = null;
      fieldSetFlags()[0] = false;
      return this;
    }

    /**
      * Gets the value of the 'cup' field.
      * @return The value.
      */
    public java.lang.Integer getCup() {
      return cup;
    }

    /**
      * Sets the value of the 'cup' field.
      * @param value The value of 'cup'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder setCup(int value) {
      validate(fields()[1], value);
      this.cup = value;
      fieldSetFlags()[1] = true;
      return this;
    }

    /**
      * Checks whether the 'cup' field has been set.
      * @return True if the 'cup' field has been set, false otherwise.
      */
    public boolean hasCup() {
      return fieldSetFlags()[1];
    }


    /**
      * Clears the value of the 'cup' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder clearCup() {
      fieldSetFlags()[1] = false;
      return this;
    }

    /**
      * Gets the value of the 'eme' field.
      * @return The value.
      */
    public java.lang.Integer getEme() {
      return eme;
    }

    /**
      * Sets the value of the 'eme' field.
      * @param value The value of 'eme'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder setEme(int value) {
      validate(fields()[2], value);
      this.eme = value;
      fieldSetFlags()[2] = true;
      return this;
    }

    /**
      * Checks whether the 'eme' field has been set.
      * @return True if the 'eme' field has been set, false otherwise.
      */
    public boolean hasEme() {
      return fieldSetFlags()[2];
    }


    /**
      * Clears the value of the 'eme' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder clearEme() {
      fieldSetFlags()[2] = false;
      return this;
    }

    /**
      * Gets the value of the 'topic' field.
      * @return The value.
      */
    public java.lang.CharSequence getTopic() {
      return topic;
    }

    /**
      * Sets the value of the 'topic' field.
      * @param value The value of 'topic'.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder setTopic(java.lang.CharSequence value) {
      validate(fields()[3], value);
      this.topic = value;
      fieldSetFlags()[3] = true;
      return this;
    }

    /**
      * Checks whether the 'topic' field has been set.
      * @return True if the 'topic' field has been set, false otherwise.
      */
    public boolean hasTopic() {
      return fieldSetFlags()[3];
    }


    /**
      * Clears the value of the 'topic' field.
      * @return This builder.
      */
    public com.pharbers.kafka.schema.SparkDriverConfig.Builder clearTopic() {
      topic = null;
      fieldSetFlags()[3] = false;
      return this;
    }

    @Override
    public SparkDriverConfig build() {
      try {
        SparkDriverConfig record = new SparkDriverConfig();
        record.name = fieldSetFlags()[0] ? this.name : (java.lang.CharSequence) defaultValue(fields()[0]);
        record.cup = fieldSetFlags()[1] ? this.cup : (java.lang.Integer) defaultValue(fields()[1]);
        record.eme = fieldSetFlags()[2] ? this.eme : (java.lang.Integer) defaultValue(fields()[2]);
        record.topic = fieldSetFlags()[3] ? this.topic : (java.lang.CharSequence) defaultValue(fields()[3]);
        return record;
      } catch (Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }

  private static final org.apache.avro.io.DatumWriter
    WRITER$ = new org.apache.avro.specific.SpecificDatumWriter(SCHEMA$);

  @Override public void writeExternal(java.io.ObjectOutput out)
    throws java.io.IOException {
    WRITER$.write(this, SpecificData.getEncoder(out));
  }

  private static final org.apache.avro.io.DatumReader
    READER$ = new org.apache.avro.specific.SpecificDatumReader(SCHEMA$);

  @Override public void readExternal(java.io.ObjectInput in)
    throws java.io.IOException {
    READER$.read(this, SpecificData.getDecoder(in));
  }

}
